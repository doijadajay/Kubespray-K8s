@@@ KUBEADM THROUGH LAUNCH K8S @@@
-----------------------------------------
{Launch 2 machines on AWS 
master
worker
instance type: t2.medium
Update security group open all TCP ports for all traffic}

Step-1) Set hostname on each nodes (both VMs)
on master- 
sudo hostnamectl set-hostname "k8s-master"

on worker-
sudo hostnamectl set-hostname "k8s-node-1"
________________________________________________________________________________________________________________________________________________________________________________

Step-2) Add the following entries in /etc/hosts files on each VMs :-
192.168.1.40    k8s-master
192.168.1.42    k8s-node-1
____________________________________________________________________________________________________________________________________________________________________________________

Step-3) Run swapoff command to disable the swap on the fly :- on both VMs

sudo swapoff -a


Next, add kernel modules and enable IP forwarding on both VMs :-

sudo tee /etc/modules-load.d/containerd.conf <<EOF
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

sudo tee /etc/sysctl.d/kubernetes.conf<<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF

sudo sysctl --system
______________________________________________________________________________________________________________________________________________________________________________________


Step-4) Install containerd runtime on all the nodes, run following set of commands,

Run Following apt command to install required dependencies for continaerd On both VMs :-

sudo apt install -y curl gnupg2 software-properties-common apt-transport-https ca-certificates

Updated command:
sudo apt update
sudo apt install -y curl gnupg software-properties-common apt-transport-https ca-certificates



Next, add docker repository on both VMs :-
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmour -o /etc/apt/trusted.gpg.d/docker.gpg
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

After adding repo, install containerd using beneath commands on both VMs :-
sudo apt update
sudo apt install -y containerd.io


Configure the contianerd using following command on both VMs :-
containerd config default | sudo tee /etc/containerd/config.toml >/dev/null 2>&1
sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml


Start and enable containerd service on both VMs :-
sudo systemctl restart containerd && sudo systemctl enable containerd


Verify containerd service, run on both VMs :-
sudo systemctl status containerd

_______________________________________________________________________________________________________________________________________________________________________________________

Step-5) Install Kubectl, kubelet and kubeadm on all nodes on both VMs :-

sudo apt install -y apt-transport-https curl 
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmour -o /etc/apt/trusted.gpg.d/kubernetes-xenial.gpg
sudo apt-add-repository "deb http://apt.kubernetes.io/ kubernetes-xenial main"
sudo apt update 
sudo apt install -y kubelet kubeadm kubectl

__________________________________________________________________________________________________________________________________________________________________________________

Step-6) Install Kubernetes Cluster using kubeadm on :
Login to your master node (k8s-master) and run below ‘kubeadm init‘ command to initialize Kubernetes cluster

sudo kubeadm init --control-plane-endpoint=k8s-master
After the initialization process completes, you’ll see a message containing a ‘kubeadm join’ command. Save this command(save token safely); we’ll use it later to add worker nodes to the cluster.
In order to interact with cluster as a regular user, let’s execute the following commands, these commands are already there in output just copy paste them:

Run following commands on both VMs :-

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

____________________________________________________________________________________________________________________________________________________________________________________

Step-7) Add Worker Nodes to Kubernetes Cluster :-
If you want to add worker nodes to your Kubernetes cluster, log in to each worker node and run the ‘kubeadm join’ command you saved from Step 5.

Copy “kubeadm join” command and paste it on (worker nodes)

sudo kubeadm join k8s-master:6443 --token zpjp2j.c0l59zbh4yw9dwfz \
--discovery-token-ca-cert-hash sha256:523b10a16d5d283f45dad330d7b8ede5b628f0e070278c03ead80683fa1b6061
________________________________________________________________________________________________________________________________________________________________________________________


step -8)
Now run kubectl comand on master VM:-

kubectl get nodes

it shows the NOt ready nodes

____________________________________________________________________________________________________________________________________________________________________________________

Step -9)
Deploy Calico Pod Network Add-on
From the master node, run the following command to install Calico pod network add-on, On master VM :-

kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml


Now run the kubectl get nodes command on master VM

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
